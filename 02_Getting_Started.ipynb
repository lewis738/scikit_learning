{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Getting_Started.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpujdpds43Tb8xSpe/q0ym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewis738/scikit_learning/blob/main/02_Getting_Started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting started**"
      ],
      "metadata": {
        "id": "tCs_mOsqJxxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting and predicting: estimator basics\n",
        "原文链接[在此](https://scikit-learn.org/stable/getting_started.html)，这个文件练习`fit`和`predict`的使用\n"
      ],
      "metadata": {
        "id": "rXh8NE6C3c7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viAy22pg11NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86667d6e-89c1-4c71-8cb7-7dad4e3a5bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn # 安装sklearn，注意全称不是sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier #引入随机森林分类器的包"
      ],
      "metadata": {
        "id": "2W7KOMFJ26Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "样例使用的是一个3个特征二分类问题，首先初始化一个随机森林估计器，然后初始化训练数据X和对应目标值Y"
      ],
      "metadata": {
        "id": "r_UqXZi95DJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(random_state=0)  \n",
        "X = [[1, 2, 3], # 2 samples, 3 features\n",
        "     [11, 12, 13]]\n",
        "Y = [0, 1]  # classes of each sample"
      ],
      "metadata": {
        "id": "z1hO1kXq3E7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkQVnaqeFxZm",
        "outputId": "96ca7bef-16d3-421b-f0ac-06420fe99f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit`方法能接受两个变量：\n",
        "\n",
        "\n",
        "\n",
        "*   `X`：样例矩阵，其尺寸为`(n_samples, n_features)`即样例数×特征数，其中每一行表示一个样例，每一列对应一个特征；\n",
        "*   `Y`：目标值，对应回归问题中的真实值，或者分类问题中代表不同类别的整数值（或其他离散值），对于无监督学习，一般不需要指定`Y`；`Y`一般是一位数组`array`，其中第`i`个记录`entry`表示`X`中第i条记录/样例的目标值。\n",
        "\n",
        "`X`和`Y`一般应为`numpy array`类新的变量，或类似的数组类型的变量，少部分的估计器需要的是其他类型（例如稀疏矩阵）。\n",
        "\n",
        "在对`estimator`使用了`fit`方法后，就能对新数据进行预测，而不需要重新进行训练。"
      ],
      "metadata": {
        "id": "Dui-QCcvF2ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(X)  # predict classes of the training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li9B_qgjF3ID",
        "outputId": "ff4afbf0-9af1-44ad-f7e9-084e6eb29dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdXBNf7ZF6p0",
        "outputId": "33f0e510-3993-4779-bd44-adc0bc18ac30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers and pre-processors\n",
        "原文链接[在此](https://scikit-learn.org/stable/getting_started.html#transformers-and-pre-processors)，这个文件练习`transformer`和`pre-processor`的使用；\n"
      ],
      "metadata": {
        "id": "cM6cJuspJ6Pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "机器学习的工作流一般包括多个步骤，一个典型的数据管道`Pipeline`一般包括数据预处理来转换或导入数据，以及一个最终的预测器`predictor`来进行目标值`Y`的预测。\n",
        "\n",
        "在`scikit-learn`中，预处理`pre-process`和数据变换`transform`遵循了估计器`estimator`对象的API（实际上他们继承了相同的`BaseEstimator`类）；但是，`transform`没有`predict`方法，而是一个`transform`方法，用于输出对样例数据`X`变换后的结果"
      ],
      "metadata": {
        "id": "VfNQEV0v8pFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler  # 数据标准化\n",
        "X = [[0, 15],\n",
        "     [1, -10]]\n",
        "# scale data according to computed scaling values\n",
        "StandardScaler().fit(X).transform(X)"
      ],
      "metadata": {
        "id": "Pt7k5dMjKEaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有时可能需要对不同的特征使用不同的数据变换方法，这时可以使用[列变换](https://scikit-learn.org/stable/modules/compose.html#column-transformer)"
      ],
      "metadata": {
        "id": "SldJX_FsKF2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelines: chaining pre-processors and estimators\n",
        "原文链接[在此](https://scikit-learn.org/stable/getting_started.html#pipelines-chaining-pre-processors-and-estimators)\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "2CouCc4RKPto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 这部分练习`Pipeline`的使用:\n",
        "\n",
        "  `transformer`和`pre-processor`可以合在一起，作为一个数据管道（`Pipeline`），数据管道（`Pipeline`）提供的功能（`API`），就像一个估计器（`estimator`）一样，可以对它使用`fit`和`predict`方法，使用`Pipeline`还可以避免数据泄露（即，在训练数据中泄露一些测试数据。后面演示）。\n",
        "\n",
        "  下面的例子中，导入[鸢尾花数据集](https://scikit-learn.org/stable/datasets.html#datasets)（`Iris dataset`），将其划分为训练集`train`和测试集`test`，最后计算`Pipeline`在训练集上的预测精度。"
      ],
      "metadata": {
        "id": "bN9MEIQY8s4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris  #Load dataset导入数据集\n",
        "from sklearn.model_selection import train_test_split  #split dataset 划分数据集为训练集和测试集用\n",
        "from sklearn.preprocessing import StandardScaler   # 数据标准化\n",
        "from sklearn.linear_model import LogisticRegression # 逻辑回归拟合器\n",
        "from sklearn.pipeline import make_pipeline  # 用于构造一个Pipeline\n",
        "from sklearn.metrics import accuracy_score  # 用于计算精确度评分\n",
        "\n",
        "# create a pipeline object 创建一个pipeline对象\n",
        "pipe = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# load the iris dataset and split it into train and test sets 导入数据集并划分train和test\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# fit the whole pipeline\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# we can now use it like any other estimator 可以看到用Pipeine和用其他estimator一样\n",
        "accuracy_score(pipe.predict(X_test), y_test)"
      ],
      "metadata": {
        "id": "iEMsB6zXKTXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "原文链接[在此](https://scikit-learn.org/stable/getting_started.html#model-evaluation)"
      ],
      "metadata": {
        "id": "QMbNlDgUK5Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这个部分练习模型评价`Model evaluation`。\n",
        "\n",
        "使用`fit`方法使模型拟合与一些数据不代表这个模型对于位置数据可能表现得很好，刚才使用了[`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)将数据划分为训练集和测试集，`scikit`中还提供了其他的工具，用于模型评价`Model evaluation`，特别是`cross-validation`。\n",
        "\n",
        "这里，我们简要地展示一下，使用[`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)执行5折交叉验证（`5-fold cross-validation`）。\n",
        "\n",
        "注意：使用不同的数据划分策略进行手动迭代、并且使用自定义的评分函数也是可以的"
      ],
      "metadata": {
        "id": "wzowHQry8w66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression  # 随机创建一个回归数据集\n",
        "from sklearn.linear_model import LinearRegression # 线性回归方法\n",
        "from sklearn.model_selection import cross_validate  # 交叉验证\n",
        "\n",
        "X, y = make_regression(n_samples=1000, random_state=0)\n",
        "lr = LinearRegression()\n",
        "\n",
        "result = cross_validate(lr, X, y)  # defaults to 5-fold CV\n",
        "result['test_score']  # r_squared score is high because dataset is easy"
      ],
      "metadata": {
        "id": "R-HwvYXyK6bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic parameter searches 自动调参\n",
        "原文链接[在此](https://scikit-learn.org/stable/getting_started.html#model-evaluation)，这里介绍自动调参的方法：\n",
        "\n"
      ],
      "metadata": {
        "id": "imWjJ0lHLTFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "所有的估计器都带有参数（专业的叫法是超参数`hyper-parameters`）可以调整，估计器的泛化能力通常极度依赖于几个参数的选取。例如：[随机森林回归`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) 有一个参数`n_estimators`控制森林中树的数量，`max_depth`控制每棵树的最大深度，一般而言，这些参数的值是未知的，因为他们取决于手中的数据。\n",
        "\n",
        "`scikit-learn`中提供了一些工具，用于自动搜索最佳的参数组合【通过交叉验证法】，在下面的例子中，我们使用[`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)对象，在随机森林的参数空间中进行随机搜索，搜索结束后，得到的[`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)对象就像使用最优参数组合进行训练`fit`后的['RandomForestRegressor'](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)对象一样。"
      ],
      "metadata": {
        "id": "_qPSATIf80zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing #  数据集\n",
        "from sklearn.ensemble import RandomForestRegressor  #随机森林回归\n",
        "from sklearn.model_selection import RandomizedSearchCV  # 基于Cv的随机搜索\n",
        "from sklearn.model_selection import train_test_split  # 数据集划分\n",
        "from scipy.stats import randint  # 均匀离散随机变量\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# define the parameter space that will be searched over\n",
        "param_distributions = {'n_estimators': randint(1, 5), # 指定搜索范围\n",
        "                       'max_depth': randint(5, 10)}\n",
        "\n",
        "# now create a searchCV object and fit it to the data\n",
        "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
        "                            n_iter=5,\n",
        "                            param_distributions=param_distributions,\n",
        "                            random_state=0)\n",
        "search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1M1JiOmQkIa",
        "outputId": "92e2d809-f94e-4891-cd7d-4d202481dd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0), n_iter=5,\n",
              "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9d8a6c5450>,\n",
              "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9d8a6c55d0>},\n",
              "                   random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.best_params_ #搜索结果"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1iHkrJCUNRo",
        "outputId": "e2fcd252-8922-476f-be01-90977c64dd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 9, 'n_estimators': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the search object now acts like a normal random forest estimator\n",
        "# with max_depth=9 and n_estimators=4\n",
        "search.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRWad_BIUO_u",
        "outputId": "e3d53244-aaaf-460b-8393-f708f85e8449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.735363411343253"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**注意：**实际中，经常希望对于一个pipeline进行参数搜索，而不只是一个estimtor；其中的主要原因是，如果不在Pipeline中进行整个数据集的数据预处理，然后使用了某种交叉验证，那么就打破了训练集和测试集间基本的的独立性性假设；实际上，因为是对整个数据集进行的数据预处理，测试集的一些信息已经透露到训练集中了，这可能导致对于估算器泛化能力的过度评价，参考这个[post](https://www.kaggle.com/alexisbcook/data-leakage)；**使用Pipeline进行交叉验证和参数搜索能够在很大程度上避开这个常见的陷阱。**"
      ],
      "metadata": {
        "id": "_OyZ2eytUysN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps 进一步学习\n"
      ],
      "metadata": {
        "id": "1HxjEqHjWYVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "本文中，简单介绍了估计器`estimator`的fitting、predicting方法、pre-processing的步骤、pipelines、cross-validation 等工具和自动的超参数搜索，这篇文章应该能够让你对sklearn这个库的主要特性有了一定的了解，但实际上还有很多内容等待你去发现。\n",
        "\n",
        "请参考[用户手册](https://scikit-learn.org/stable/user_guide.html#user-guide)获取关于更多工具的详细内容，[公共API的详尽列表可以在这里找到](https://scikit-learn.org/stable/modules/classes.html#api-ref)\n",
        "\n",
        "还可以查看在许多不同的场景中使用`scikit-learn`的[例子](https://scikit-learn.org/stable/auto_examples/index.html#general-examples)\n",
        "\n",
        "[教程页面](https://scikit-learn.org/stable/tutorial/index.html#tutorial-menu)还含有很多学习资源"
      ],
      "metadata": {
        "id": "QVWDmMvK837W"
      }
    }
  ]
}